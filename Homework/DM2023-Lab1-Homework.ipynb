{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FDNTc1wFid-1"
   },
   "source": [
    "### Student Information\n",
    "Name:林明杉\n",
    "\n",
    "Student ID:108012007\n",
    "\n",
    "GitHub ID: max-lin-texan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-BajKEF_id-5"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rSzgpPbVid-6"
   },
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UjbdfsDcid-6"
   },
   "source": [
    "1. First: do the **take home** exercises in the [DM2023-Lab1-Master](https://github.com/fjrialdnc0615/DM2023-Lab1-Master). You may need to copy some cells from the Lab notebook to this notebook. __This part is worth 20% of your grade.__\n",
    "\n",
    "\n",
    "2. Second: follow the same process from the [DM2023-Lab1-Master](https://github.com/fjrialdnc0615/DM2023-Lab1-Master) on **the new dataset**. You don't need to explain all details as we did (some **minimal comments** explaining your code are useful though).  __This part is worth 30% of your grade.__\n",
    "    - Download the [the new dataset](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences#). The dataset contains a `sentence` and `score` label. Read the specificiations of the dataset for details. You need to combine three labeled datasets into one file for your data preparation part.\n",
    "    - You are allowed to use and modify the `helper` functions in the folder of the first lab session (notice they may need modification) or create your own.\n",
    "\n",
    "\n",
    "3. Third: please attempt the following tasks on **the new dataset**. __This part is worth 30% of your grade.__\n",
    "    - Generate meaningful **new data visualizations**. Refer to online resources and the Data Mining textbook for inspiration and ideas. \n",
    "    - Generate **TF-IDF features** from the tokens of each text. This will generating a document matrix, however, the weights will be computed differently (using the TF-IDF value of each word per document as opposed to the word frequency). Refer to this Sciki-learn [guide](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) .\n",
    "    - Implement a simple **Naive Bayes classifier** that automatically classifies the records into their categories. Use both the TF-IDF features and word frequency features to build two seperate classifiers. Comment on the differences.  Refer to this [article](https://hub.packtpub.com/implementing-3-naive-bayes-classifiers-in-scikit-learn/).\n",
    "\n",
    "\n",
    "4. Fourth: In the lab, we applied each step really quickly just to illustrate how to work with your dataset. There are somethings that are not ideal or the most efficient/meaningful. Each dataset can be habdled differently as well. What are those inefficent parts you noticed? How can you improve the Data preprocessing for these specific datasets? __This part is worth 10% of your grade.__\n",
    "\n",
    "\n",
    "5. Fifth: It's hard for us to follow if your code is messy, so please **tidy up your notebook** and **add minimal comments where needed**. __This part is worth 10% of your grade.__\n",
    "\n",
    "\n",
    "You can submit your homework following these guidelines: [Git Intro & How to hand your homework](https://github.com/fjrialdnc0615/DM2023-Lab1-Master/blob/main/Git%20Intro%20%26%20How%20to%20hand%20your%20homework.ipynb). Make sure to commit and save your changes to your repository __BEFORE the deadline (October 27th 11:59 pm, Thursday)__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 285,
     "status": "ok",
     "timestamp": 1666241724343,
     "user": {
      "displayName": "Kevin Yang",
      "userId": "04518680380941289042"
     },
     "user_tz": -480
    },
    "id": "IDH6foBIid-9"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/y5/ph990zwj3xg388wjlcf1_33h0000gn/T/ipykernel_53488/3196143558.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# I tried double locs with function \"lambda\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "#EX2\n",
    "\n",
    "X.loc[lambda X: X['category'] != 1, :].loc[10:100]\n",
    "# I tried double locs with function \"lambda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EX5\n",
    "\n",
    "#Since 'NaN', 'None' and '' are all string type, they will be detected as string instead of NaN type.\n",
    "#Hence, the isnull() function will return three \"True\" values, not all \"False\" values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EX6\n",
    "\n",
    "#Changes: 1. Length: We set the sampling length to be 1000, and the original length of X is 2257.\n",
    "#Changes: 2. Order: The X_sample's order is based on random state, and the original order of X is same as the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/y5/ph990zwj3xg388wjlcf1_33h0000gn/T/ipykernel_53488/398546266.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# plot barchart for X_sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategory_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mupper_bound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategory_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#277 + 50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategory_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_sample' is not defined"
     ]
    }
   ],
   "source": [
    "#EX7\n",
    "\n",
    "# It is possible, we can assign a parameter exceeding maximum number of name counts for a little. Then use this parameter as the upperbound of ylim.\n",
    "# Hence we don't need to set a specific number as an upperbound. We will automatically have a proper ylim.\n",
    "\n",
    "# plot barchart for X_sample\n",
    "print(max(X_sample.category_name.value_counts()))\n",
    "upper_bound = max(X_sample.category_name.value_counts() + 50) #277 + 50\n",
    "print(X_sample.category_name.value_counts())\n",
    "\n",
    "X_sample.category_name.value_counts().plot(kind = 'bar',\n",
    "                                           title = 'Category distribution',\n",
    "                                           ylim = [0, upper_bound], \n",
    "                                           rot = 0, fontsize = 12, figsize = (8,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/y5/ph990zwj3xg388wjlcf1_33h0000gn/T/ipykernel_53488/1892099237.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#EX8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mupper_bound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategory_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mS1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategory_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mD1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mS1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "#EX8\n",
    "\n",
    "upper_bound = max(X.category_name.value_counts() + 100)\n",
    "S1 = X.category_name.value_counts()\n",
    "D1 = S1.to_frame()\n",
    "S2 = X_sample.category_name.value_counts()\n",
    "D2 = S2.to_frame()\n",
    "\n",
    "S2.plot(x = 1, kind = 'bar',\n",
    "        color = 'orange',\n",
    "      title = 'Category distribution',\n",
    "      ylim = [0, upper_bound], \n",
    "      rot = 0, fontsize = 12, figsize = (8,3),\n",
    "       width = 0.2,\n",
    "       zorder = 2)\n",
    "S2.name = (\"category_name\")\n",
    "plt.legend(loc = 'upper right')\n",
    "\n",
    "S1.plot(x = 2, kind = 'bar',\n",
    "        color = 'blue',\n",
    "      title = 'Category distribution',\n",
    "      ylim = [0, upper_bound], \n",
    "      rot = 0, fontsize = 12, figsize = (8,3),\n",
    "       width = 0.2,\n",
    "       zorder = 1)\n",
    "S1.name = (\"category_name\")\n",
    "plt.legend(loc = 'upper right')\n",
    "\n",
    "\n",
    "\n",
    "# I cannot convert stacked bar chart to unstacked bar chart using Series instead of DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'count_vect' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/y5/ph990zwj3xg388wjlcf1_33h0000gn/T/ipykernel_53488/806029484.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#EX10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_vect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'count_vect' is not defined"
     ]
    }
   ],
   "source": [
    "#EX10\n",
    "\n",
    "words = count_vect.get_feature_names_out()\n",
    "for i in range(0,len(X)):\n",
    "    for j in range(0,len(words)):\n",
    "        if X_counts[i:i+1, j:j+1] == 1:\n",
    "               print(words[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EX11\n",
    "\n",
    "# Filtering the total appearance in all the documents for all vocabs, and delete those who have 0 appearance in total.\n",
    "\n",
    "plot_x = [\"term_\" + str(i) for i in count_vect.get_feature_names_out()[:]]\n",
    "plot_y = [\"doc_\" + str(i) for i in list(X.index)[:]]\n",
    "record = []\n",
    "for x in range(0,len(plot_x)):\n",
    "    temp = X_counts[:,x:x+1].toarray()\n",
    "    if sum(temp[0]) != 0:\n",
    "        record.append(x)\n",
    "\n",
    "\n",
    "       \n",
    "plot_z = X_counts[:, record].toarray()\n",
    "plot_x = [\"term_\"+str(i) for i in count_vect.get_feature_names_out()[record]]\n",
    "\n",
    "#df_todraw = pd.DataFrame(plot_z, columns = plot_x, index = plot_y)\n",
    "#display(df_todraw)\n",
    "#plt.subplots(figsize=(9, 7))\n",
    "#ax = sns.heatmap(df_todraw,\n",
    "#                 cmap=\"PuRd\",\n",
    "#                 vmin=0, vmax=1, annot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EX12\n",
    "\n",
    "print(X_counts)\n",
    "X_reduced_new = PCA(n_components = 3).fit_transform(X_counts.toarray())\n",
    "print(X_reduced_new)\n",
    "\n",
    "\n",
    "ax = plt.figure(figsize = (25,10)).add_subplot(projection='3d')\n",
    "\n",
    "col = ['coral', 'blue', 'black', 'orange']\n",
    "for c, category in zip(col, categories):\n",
    "    xs = X_reduced_new[X['category_name'] == category].T[0]\n",
    "    ys = X_reduced_new[X['category_name'] == category].T[1]\n",
    "    zs = X_reduced_new[X['category_name'] == category].T[2]\n",
    "   \n",
    "    ax.scatter(xs, ys, zs, c = c, marker='o')\n",
    "\n",
    "ax.grid(color='gray', linestyle=':', linewidth=2, alpha=0.2)\n",
    "ax.set_xlabel('\\nX Label')\n",
    "ax.set_ylabel('\\nY Label')\n",
    "ax.set_zlabel('\\nZ Label')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EX13\n",
    "\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "X = count_vect.get_feature_names_out()[:300]\n",
    "Y = term_frequencies[:300]\n",
    "DF = pd.DataFrame(dict(features_name = X, term_frequencies = Y))\n",
    "figure = px.bar(DF, x = 'features_name', y = 'term_frequencies')\n",
    "\n",
    "figure.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EX14\n",
    "\n",
    "# I try to reduce the number to about 30, remaining only about 10% of original data.\n",
    "# The criteria is to ignore the features_name with too little frequencies or almost with zero frequency.\n",
    "\n",
    "X = count_vect.get_feature_names_out()[:300] #original\n",
    "Y = term_frequencies[:300]\n",
    "\n",
    "X_new = []\n",
    "Y_new = []\n",
    "\n",
    "order = sorted(Y)[-30:]\n",
    "criteria = order[0]\n",
    "\n",
    "for i in range(0,len(X)):\n",
    "    if(Y[i] >= criteria):\n",
    "        X_new.append(X[i])\n",
    "        Y_new.append(Y[i])\n",
    "\n",
    "DF = pd.DataFrame(dict(features_name = X_new, term_frequencies = Y_new))\n",
    "figure = px.bar(DF, x = 'features_name', y = 'term_frequencies')\n",
    "\n",
    "figure.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EX15\n",
    "\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "#count_vect.get_feature_names_out()[:300]\n",
    "TF = sorted(term_frequencies[:300])\n",
    "\n",
    "SSTF = sorted(set(TF))\n",
    "\n",
    "FREQ = []\n",
    "for i in SSTF:\n",
    "    FREQ.append(list(TF).count(i) - 1)\n",
    "\n",
    "\n",
    "SSTF = np.array(SSTF)\n",
    "FREQ = np.array(FREQ)\n",
    "\n",
    "area_under_curve = np.trapz(FREQ, SSTF)\n",
    "target_area = area_under_curve / 2.0\n",
    "x_cut = 0\n",
    "\n",
    "for i in range(len(SSTF) - 1):\n",
    "    area = np.trapz(FREQ[:i+1], SSTF[:i+1])\n",
    "    if area > target_area:\n",
    "        x_cut = SSTF[i]\n",
    "        break\n",
    "x_smooth = np.linspace(SSTF.min(), SSTF.max(), 1000)\n",
    "spl = make_interp_spline(SSTF, FREQ, k=3)  # Cubic spline interpolation\n",
    "y_smooth = spl(x_smooth)\n",
    "\n",
    "plt.plot(SSTF, FREQ)\n",
    "\n",
    "plt.axis('off')\n",
    "\n",
    "plt.axvline(x = x_cut, color='r', linestyle='-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EX16\n",
    "\n",
    "New = preprocessing.LabelBinarizer()\n",
    "New.fit(X.category_name)\n",
    "X['bin_category'] = New.transform(X['category_name']).tolist()\n",
    "X[0:9]\n",
    "\n",
    "#It also works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "PQPCUbx1ie4R",
    "8qg4up1B_EhD",
    "lC7ymUlG_fai",
    "xtvWLH1x_7nV",
    "bgULadKFBXL-",
    "SZ4rgA1mBir5",
    "9VirxMl6CGN2",
    "yoTS9Vh8ESzB",
    "NGVM3wSjFt7v",
    "bH9BQLSWF9Uf",
    "y8I6L8Z8JGsv",
    "TFIl1hpMJqnv",
    "DobYRQ4FLetu",
    "9pfemrkcLiUG"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
